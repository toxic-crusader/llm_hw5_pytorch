{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c17802c2",
   "metadata": {},
   "source": [
    "# Animal Faces\n",
    "\n",
    "## Задание:\n",
    "\n",
    "Необходимо реализовать систему классификации лиц животных. Задача представляет из себя классификацию на 3 класса.\n",
    "\n",
    "1) Необходимо загрузить изображения и привести их к единому формату. Важно понимать, что исходное разрешение очень больше, и простые сети на несколько слоев могут выдать не такое хорошее качество.\n",
    "\n",
    "2) Необходимо обучить нейросеть для распознавания 3 классов, желательно будет сравнить результаты на нескольких параметрах.\n",
    "\n",
    "3) Оценить по метрикам качества для каждого класса.\n",
    "\n",
    "Важно визуализировать результат прогноза (на тесте) в человеко-читаемом формате с подписью."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50605a24",
   "metadata": {},
   "source": [
    "### Подготовка данных\n",
    "\n",
    "На этом этапе выполняется подготовка датасета для дальнейшего обучения нейросети.  \n",
    "Исходные изображения загружаются из Kaggle с помощью kagglehub и сохраняются локально без изменения оригинальной структуры.\n",
    "\n",
    "Далее выполняется предварительная обработка изображений. Все файлы приводятся к единому формату, цветовой модели RGB и фиксированному размеру. Результат сохраняется в отдельную директорию processed, при этом полностью сохраняется исходная иерархия папок train, val и классов.\n",
    "\n",
    "Такой подход позволяет не изменять исходные данные, ускоряет дальнейшую загрузку изображений и делает эксперименты воспроизводимыми. Аугментации на этом этапе не применяются и будут добавлены позже при обучении модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f62596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Downloading dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Dataset id `andrewmvd/animal-faces`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Target directory `/home/garret/git/mfti/llm_hw5_pytorch/data/animal-faces`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Force download `False`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Download skipped"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Dataset already exists locally"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Preprocessing dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Source directory `/home/garret/git/mfti/llm_hw5_pytorch/data/animal-faces`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Target directory `/home/garret/git/mfti/llm_hw5_pytorch/data/processed`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Image size `224 x 224`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Force reprocessing `False`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Preprocessing finished"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Processed images `16130`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Skipped images `0`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scripts.download import download_dataset\n",
    "from scripts.preprocess import preprocess_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "raw_data_dir: Path = download_dataset(dataset_id=\"andrewmvd/animal-faces\", target_dir=\"data/animal-faces\")\n",
    "processed_data_dir = \"data/processed\"\n",
    "\n",
    "processed_path: Path = preprocess_dataset(\n",
    "    raw_dir=raw_data_dir,\n",
    "    processed_dir=processed_data_dir,\n",
    "    image_size=224,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c81c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Loading processed dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Dataset directory `/home/garret/git/mfti/llm_hw5_pytorch/data/processed/afhq`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Batch size `32`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Dataset loaded"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Number of classes `3`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Class names `['cat', 'dog', 'wild']`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Train samples `14630`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Validation samples `1500`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]), ['cat', 'dog', 'wild'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.data import make_dataloaders\n",
    "\n",
    "processed_path = processed_path / \"afhq\"\n",
    "train_loader, val_loader, class_names = make_dataloaders(\n",
    "    data_dir=processed_path,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "images.shape, labels.shape, class_names\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw5-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
